"""
Example routes demonstrating Enhanced XSS Protection usage.

This file shows how to implement the enhanced security features
in your Flask routes for NextProperty AI.
"""

from flask import Blueprint, request, jsonify, render_template, flash, redirect, url_for
from app.security.enhanced_integration import (
    enhanced_security_protect, 
    admin_security_protect,
    api_security_protect,
    upload_security_protect,
    enhanced_security
)
from app.security.advanced_validation import advanced_validator, InputType, ValidationResult
from app.security.advanced_xss import advanced_xss, Context
from app.security.enhanced_csp import csp_manager
from flask import g, current_app

# Create blueprint for example routes
security_examples_bp = Blueprint('security_examples', __name__, url_prefix='/security-examples')


@security_examples_bp.route('/public-form', methods=['GET', 'POST'])
@enhanced_security_protect(context='public', block_on_threat=True)
def public_form_example():
    """Example of a public form with enhanced security protection."""
    
    if request.method == 'POST':
        # Access security report generated by decorator
        security_report = getattr(g, 'security_report', None)
        
        if security_report:
            current_app.logger.info(f"Security analysis: {security_report.recommendation}")
            
            # Check for high-risk content in form data
            if security_report.validation_reports:
                for field, report in security_report.validation_reports.items():
                    if report.result == ValidationResult.SUSPICIOUS:
                        flash(f"Suspicious content detected in {field}. Input has been sanitized.", "warning")
                    elif report.result == ValidationResult.MALICIOUS:
                        flash(f"Malicious content blocked in {field}.", "error")
                        return redirect(url_for('security_examples.public_form_example'))
        
        # Process sanitized form data
        name = request.form.get('name', '')
        message = request.form.get('message', '')
        email = request.form.get('email', '')
        
        # Additional manual validation if needed
        email_validation = advanced_validator.validate_input(email, InputType.EMAIL)
        if email_validation.result not in [ValidationResult.SAFE, ValidationResult.SUSPICIOUS]:
            flash("Invalid email address format.", "error")
            return redirect(url_for('security_examples.public_form_example'))
        
        flash("Form submitted successfully with enhanced security protection!", "success")
        return redirect(url_for('security_examples.public_form_example'))
    
    return render_template('security_examples/public_form.html')


@security_examples_bp.route('/admin-panel')
@admin_security_protect
def admin_panel_example():
    """Example of admin panel with maximum security protection."""
    
    # Access security report
    security_report = getattr(g, 'security_report', None)
    
    # Admin panels get the highest security level
    security_metrics = enhanced_security.get_security_metrics(3600)  # Last hour
    
    return render_template('security_examples/admin_panel.html', 
                         security_metrics=security_metrics,
                         security_report=security_report)


@security_examples_bp.route('/api/secure-endpoint', methods=['POST'])
@api_security_protect
def secure_api_example():
    """Example of API endpoint with enhanced security protection."""
    
    # Get the security analysis report
    security_report = getattr(g, 'security_report', None)
    
    # API endpoints get enhanced protection without CSP
    if not request.is_json:
        return jsonify({'error': 'Content-Type must be application/json'}), 400
    
    data = request.get_json()
    
    # Validate specific fields with advanced validation
    if 'search_query' in data:
        query_validation = advanced_validator.validate_input(
            data['search_query'], 
            InputType.TEXT, 
            context='search'
        )
        
        if query_validation.result == ValidationResult.BLOCKED:
            return jsonify({
                'error': 'Search query blocked due to security policy',
                'recommendation': query_validation.recommendation
            }), 403
        
        # Use sanitized content
        if query_validation.sanitized_input:
            data['search_query'] = query_validation.sanitized_input
    
    # Process the secure API request
    response_data = {
        'status': 'success',
        'message': 'API request processed with enhanced security',
        'security_info': {
            'threat_level': security_report.overall_threat_level.name if security_report else 'UNKNOWN',
            'processing_time': security_report.processing_time if security_report else 0.0
        }
    }
    
    return jsonify(response_data)


@security_examples_bp.route('/upload', methods=['GET', 'POST'])
@upload_security_protect
def file_upload_example():
    """Example of file upload with comprehensive security scanning."""
    
    if request.method == 'POST':
        if 'file' not in request.files:
            flash('No file selected', 'error')
            return redirect(request.url)
        
        file = request.files['file']
        if file.filename == '':
            flash('No file selected', 'error')
            return redirect(request.url)
        
        # Enhanced file security validation
        file_content = file.read()
        file.seek(0)  # Reset file pointer
        
        # Validate file with enhanced security
        security_report = enhanced_security.validate_file_upload(
            file_content, 
            file.filename, 
            context='upload'
        )
        
        if security_report.overall_threat_level.name == 'CRITICAL':
            flash('File upload blocked due to critical security threat', 'error')
            current_app.logger.error(f"Critical file upload threat: {security_report.recommendation}")
            return redirect(request.url)
        
        elif security_report.overall_threat_level.name == 'HIGH':
            flash('File upload quarantined for review due to high security risk', 'warning')
            current_app.logger.warning(f"High-risk file upload: {security_report.recommendation}")
            # In production, you might quarantine the file for manual review
            return redirect(request.url)
        
        elif security_report.overall_threat_level.name == 'MEDIUM':
            flash('File upload processed with additional security scanning', 'info')
        
        # File is safe to process
        flash(f'File {file.filename} uploaded successfully with enhanced security validation', 'success')
        
        # Here you would save the file with additional security measures
        # secure_filename = werkzeug.utils.secure_filename(file.filename)
        # file.save(os.path.join(app.config['UPLOAD_FOLDER'], secure_filename))
        
        return redirect(request.url)
    
    return render_template('security_examples/file_upload.html')


@security_examples_bp.route('/content-analysis', methods=['POST'])
@enhanced_security_protect(context='public')
def content_analysis_example():
    """Example of manual content analysis using advanced XSS protection."""
    
    content = request.form.get('content', '')
    context_type = request.form.get('context', 'html')
    
    # Map context string to Context enum
    context_map = {
        'html': Context.HTML,
        'javascript': Context.JAVASCRIPT,
        'css': Context.CSS,
        'url': Context.URL,
        'json': Context.JSON,
        'text': Context.TEXT
    }
    
    analysis_context = context_map.get(context_type, Context.HTML)
    
    # Perform advanced XSS analysis
    analysis = advanced_xss.analyze_content(content, analysis_context)
    
    # Prepare response
    response_data = {
        'threat_level': analysis.threat_level.name,
        'score': analysis.score,
        'patterns_detected': analysis.patterns_detected,
        'context_violations': analysis.context_violations,
        'blocked': analysis.blocked,
        'reason': analysis.reason,
        'sanitized_content': analysis.sanitized_content
    }
    
    return jsonify(response_data)


@security_examples_bp.route('/security-metrics')
@admin_security_protect
def security_metrics_example():
    """Example of security metrics dashboard."""
    
    # Get comprehensive security metrics
    metrics = enhanced_security.get_security_metrics(3600)  # Last hour
    
    # Get CSP violation statistics
    csp_violations = csp_manager.get_violation_stats(3600)
    
    # Combine metrics
    comprehensive_metrics = {
        'security_metrics': metrics,
        'csp_violations': csp_violations,
        'blocked_ips': len(enhanced_security.blocked_ips),
        'rate_limited_ips': len([
            ip for ip, expiry in enhanced_security.rate_limited_ips.items()
            if expiry > time.time()
        ])
    }
    
    return jsonify(comprehensive_metrics)


@security_examples_bp.route('/csp-report', methods=['POST'])
def csp_violation_report():
    """Endpoint for receiving CSP violation reports."""
    
    try:
        # Parse CSP violation report
        report_data = request.get_json()
        if not report_data:
            return '', 400
        
        # Process with enhanced CSP manager
        violation = csp_manager.process_violation_report(report_data)
        
        # Log the violation
        current_app.logger.warning(f"CSP Violation: {violation.directive} blocked {violation.blocked_uri}")
        
        return '', 204  # No content response
        
    except Exception as e:
        current_app.logger.error(f"Error processing CSP violation report: {e}")
        return '', 500


# Context processor to add security nonce to templates
@security_examples_bp.app_context_processor
def inject_security_context():
    """Inject security context into templates."""
    
    nonce = None
    try:
        nonce = csp_manager.get_current_nonce()
    except:
        pass
    
    return {
        'csp_nonce': nonce,
        'security_report': getattr(g, 'security_report', None)
    }


# Error handler for security-related errors
@security_examples_bp.errorhandler(403)
def handle_security_error(error):
    """Handle security-related 403 errors."""
    
    security_report = getattr(g, 'security_report', None)
    
    if request.is_json:
        return jsonify({
            'error': 'Access denied due to security policy',
            'security_info': {
                'threat_level': security_report.overall_threat_level.name if security_report else 'UNKNOWN',
                'recommendation': security_report.recommendation if security_report else 'Request blocked'
            }
        }), 403
    
    return render_template('security_examples/security_error.html', 
                         security_report=security_report), 403


# Example of manual security integration in a route
@security_examples_bp.route('/manual-security-check', methods=['POST'])
def manual_security_check():
    """Example of manual security integration without decorators."""
    
    # Manual security analysis
    security_report = enhanced_security.analyze_request('public')
    
    # Check threat level manually
    if security_report.overall_threat_level.name in ['CRITICAL', 'HIGH']:
        current_app.logger.warning(f"Manual security check blocked request: {security_report.recommendation}")
        return jsonify({'error': 'Request blocked due to security analysis'}), 403
    
    # Process request with security context
    user_input = request.form.get('user_input', '')
    
    # Manual input validation
    validation = advanced_validator.validate_input(user_input, InputType.TEXT)
    
    if validation.result == ValidationResult.BLOCKED:
        return jsonify({'error': 'Input blocked by security validation'}), 400
    
    # Use sanitized input
    safe_input = validation.sanitized_input or user_input
    
    return jsonify({
        'status': 'success',
        'processed_input': safe_input,
        'security_info': {
            'threat_level': security_report.overall_threat_level.name,
            'validation_result': validation.result.value,
            'processing_time': security_report.processing_time
        }
    })


import time
